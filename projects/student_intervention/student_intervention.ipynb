{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "### Question:\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "This is a classification problem. The output takes on class labels (classification), not continuous values (regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n",
    "\n",
    "_To execute a code cell, click inside it and press **Shift+Enter**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students = len(student_data)\n",
    "n_features = len(student_data.columns) - 1\n",
    "n_passed = len([s for s in student_data['passed'] if s == 'yes'])\n",
    "n_failed = n_students - n_passed\n",
    "grad_rate = 100.0 * n_passed / n_students\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=num_train)\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.008\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "print clf  # you can inspect the learned model by printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.006\n",
      "F1 score for training set: 0.877272727273\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print \"F1 score for training set: {}\".format(train_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.851612903226\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "### Complexity\n",
    "\n",
    "Computational: \n",
    "\n",
    "Training: O(max(n,d)  min(n,d)^2), where n is the number of points, and d is the number of dimensions [1]. \n",
    "\n",
    "Testing: depends on the kernel used.\n",
    "\n",
    "Space: O(n^2) [2].\n",
    "\n",
    "### General Applications\n",
    "\n",
    "* Data with large numbers of features\n",
    "\n",
    "* Text and hypertext categorization\n",
    "* Image classification\n",
    "\n",
    "### Strengths\n",
    "\n",
    "* Effective when there are large numbers of features\n",
    "* Decision function is memory-efficient\n",
    "\n",
    "### Weaknesses\n",
    "\n",
    "* Does not directly give probability estimates - they have to be computed seperately & expensively\n",
    "* If # features >> # samples, SVNs will perform poorly\n",
    "* More applicable to binary problems\n",
    "\n",
    "\n",
    "### Why choose this model?\n",
    "\n",
    "There are quite a few features in our data and not too many data points to support the potential complexity that any model will end up with to handle that many features - SVNs will perform acceptably in this case. I'm interested to see how it compares to other models. It is also a binary classification model - which is relevant to our data (multiclass SVM models also exist).\n",
    "\n",
    "[1] Chapelle, Olivier. \"Training a support vector machine in the primal.\" Neural Computation 19.5 (2007): 1155-1178.\n",
    "\n",
    "[2] http://www.jmlr.org/papers/volume6/tsang05a/tsang05a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "===SVC===\n",
      "=========\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.011\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "F1 score for training set: 0.877272727273\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.851612903226\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.87898089172\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.853658536585\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.004\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for training set: 0.894915254237\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.826666666667\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.011\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.006\n",
      "F1 score for training set: 0.877272727273\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.851612903226\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "# TODO: Run the helper function above for desired subsets of training data\n",
    "# Note: Keep the test set constant\n",
    "print \"=========\"\n",
    "print \"===SVC===\"\n",
    "print \"=========\"\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train[0:300], y_train[0:300], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest of Randomized Trees\n",
    "\n",
    "### Complexity\n",
    "\n",
    "Computational: \n",
    "\n",
    "Training: O(t*m*n*log n) where t is the number of decision trees, m is the number of features, and n is the number of data points.\n",
    "\n",
    "Testing: O(t*log(n))\n",
    "\n",
    "Space: O(t*2^m)\n",
    "\n",
    "### General Applications\n",
    "\n",
    "* Very flexible across predictive applications\n",
    "* Not appropriate for descriptive applications\n",
    "\n",
    "### Strengths\n",
    "\n",
    "* Fast to train\n",
    "* Can make speed/performance tradeoff by tuning parameters\n",
    "* Flexible across many/few features, many/few data points\n",
    "\n",
    "### Weaknesses\n",
    "\n",
    "* Slow to make predictions once trained\n",
    "* Results of learning are not descriptive/understandable\n",
    "\n",
    "### Why choose this model?\n",
    "\n",
    "It can perform acceptably with many features and few data points. It would be interesting to see the speed/performance tradeoff for this data set - since our data set is small and we will predict in small volumes, we can lean towards performance.\n",
    "\n",
    "### Notes\n",
    "\n",
    "Changing the number of estimators in the classifier by an order or magnitude (1, 10, 100) appeared to change the F1 score by ~3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "===RFC===\n",
      "=========\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.029\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.882217090069\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.847682119205\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.020\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.926174496644\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.84076433121\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.023\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.91095890411\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.813793103448\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.041\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.878378378378\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.838709677419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "# scikit-learn recommends max_depth=sqrt(n_features)\n",
    "# http://scikit-learn.org/stable/modules/ensemble.html#parameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=12, \n",
    "    max_depth=int(math.sqrt(n_features))\n",
    ")\n",
    "print \"=========\"\n",
    "print \"===RFC===\"\n",
    "print \"=========\"\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train[0:300], y_train[0:300], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours\n",
    "\n",
    "### Complexity\n",
    "\n",
    "Computational:\n",
    "\n",
    "Training (when pre-processing k): O(n*m) where n is the number of data points and m is the number of features\n",
    "\n",
    "Testing: O(n*m)\n",
    "\n",
    "Space: O(n*m)\n",
    "\n",
    "### General Applications\n",
    "* Economic forecasting [1]\n",
    "* Breast cancer diagnoses [2]\n",
    "\n",
    "### Strengths\n",
    "\n",
    "* Simple and easy to implement\n",
    "* Nearest Neighbours is used for clustering\n",
    "\n",
    "### Weaknesses\n",
    "\n",
    "* Does not 'learn' anything from training data - just uses the entire set of training data for classification\n",
    "* Slow for large samples\n",
    "* Changing K can change class labels\n",
    "* Not robust to noisy data\n",
    "* Does not give probabilistic output\n",
    "\n",
    "### Why choose this model?\n",
    "\n",
    "I'm curious how a type of model more often used for clustering would perform at prediction.\n",
    "\n",
    "[1] http://www.ijera.com/papers/Vol3_issue5/DI35605610.pdf\n",
    "\n",
    "[2] http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2243774/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "===KNN===\n",
      "=========\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.013\n",
      "F1 score for training set: 0.849765258216\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.040\n",
      "F1 score for test set: 0.813793103448\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.838709677419\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.802631578947\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.005\n",
      "F1 score for training set: 0.863945578231\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.8\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.010\n",
      "F1 score for training set: 0.849765258216\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for test set: 0.813793103448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "print \"=========\"\n",
    "print \"===KNN===\"\n",
    "print \"=========\"\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train[0:300], y_train[0:300], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?\n",
    "\n",
    "### Best Model\n",
    "\n",
    "K Nearest Neighbours is the model I would recommend. Predictive performance is the deciding factor of model choice, as long as the time and space complexities don't make the model unreasonable to use. Here is a summary of the model performances on the whole dataset:\n",
    "\n",
    "#### K Nearest Neighbours\n",
    "\n",
    "* Training time: 0.001 sec\n",
    "* Prediction time: 0.007 sec\n",
    "* Training F1 Score: ~0.87\n",
    "* Testing F1 Score: ~0.80\n",
    "\n",
    "#### Forest of Randomized Decision Trees\n",
    "\n",
    "* Training time: 0.011 sec\n",
    "* Prediction time: 0.010 sec\n",
    "* Training F1 Score: ~0.89\n",
    "* Testing F1 Score: ~0.77 - 0.80\n",
    "\n",
    "#### SVC\n",
    "\n",
    "* Training time: 0.001 sec\n",
    "* Prediction time: 0.007 sec\n",
    "* Training F1 Score: ~0.87\n",
    "* Testing F1 Score: ~0.78 - 0.8\n",
    "\n",
    "K Nearest Neighbours performs best at Testing F1 score. Not only is it always higher than the other methods, but it is consistent given the same training/test split- unlike the others which vary in performance every execution on the same training/test data split. KNN also has closer Training and Testing F1 scores - which indicates that it is not overfitting as much as the other models.\n",
    "\n",
    "KNN has significant disadvantages which don't appear to prevent from it being the best choice. The prediction time will scale quickly with data points. In this case, there were 300 training points, ~100 testing points, and x features. Prediction time on my computer was 0.007 sec = O(x * 300) * 100 which means each prediction will take about 0.00000023 * # training points. If there are 10000 students that took a particular course in the past, and you have to make predictions on that course for 500 new students, it will take ~1.17 sec to perform all the predictions. This appears to be tolerable. If this dataset was a few orders of magnitude larger, KNN would be unreasonable.\n",
    "\n",
    "Finally, we don't seem to need to understand how the model is making predictions (we don't care about descriptiveness), so KNN does not fail us in that respect.\n",
    "\n",
    "### How the Model Works\n",
    "\n",
    "During training, KNN simply stores each data point (the student and all their properties) and the class it belongs to (whether the student passed or failed). When predicting what class a new data point should belong to (whether or not a new student will pass), KNN finds the top k most similar data points (where k is some number we chose beforehand). The class we predict for the new data point is the most commonly found class in the k data points we just found. The way we define how 'similar' any two data points are can be customized, but there are some commonly-used ways to choose from.\n",
    "\n",
    "\n",
    "### Final Score\n",
    "\n",
    "~0.80\n",
    "\n",
    "Surprisingly, GridSearchCV (consistently) picked a set of parameters that performed marginally worse than the default parameters. GridSearchCV must have performed a different split on the training data to test which one performs best (so the training data used to train wasn't the exact same for the grid search vs trial with default  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.007\n",
      "F1 score for training set: 0.803493449782\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.828947368421\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=30, p=2,\n",
      "           weights='uniform')\n",
      "0.801677746122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    return f1_score(y_true, y_predict, pos_label='yes')\n",
    "\n",
    "scoring_function = make_scorer(\n",
    "    performance_metric,\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "parameters_to_tune = {\n",
    "    'n_neighbors': (1, 2, 5, 8, 10, 15, 30, 50),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'algorithm': ('ball_tree', 'kd_tree', 'brute')\n",
    "}\n",
    "\n",
    "\n",
    "best_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    parameters_to_tune,\n",
    "    scoring=scoring_function\n",
    ")\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "train_predict(best_knn.best_estimator_, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print best_knn.best_estimator_\n",
    "print best_knn.best_score_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
